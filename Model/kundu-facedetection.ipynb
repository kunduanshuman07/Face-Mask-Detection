{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-18T15:19:07.595735Z","iopub.status.busy":"2023-09-18T15:19:07.595242Z","iopub.status.idle":"2023-09-18T15:19:14.867535Z","shell.execute_reply":"2023-09-18T15:19:14.866523Z","shell.execute_reply.started":"2023-09-18T15:19:07.595682Z"},"trusted":true},"outputs":[],"source":["# Organizing Input Data\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:19:14.873416Z","iopub.status.busy":"2023-09-18T15:19:14.869177Z","iopub.status.idle":"2023-09-18T15:19:14.880379Z","shell.execute_reply":"2023-09-18T15:19:14.879110Z","shell.execute_reply.started":"2023-09-18T15:19:14.873368Z"},"trusted":true},"outputs":[],"source":["with_mask_data = os.listdir('/kaggle/input/face-mask-dataset/data/with_mask/')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:19:14.881833Z","iopub.status.busy":"2023-09-18T15:19:14.881493Z","iopub.status.idle":"2023-09-18T15:19:14.896925Z","shell.execute_reply":"2023-09-18T15:19:14.895334Z","shell.execute_reply.started":"2023-09-18T15:19:14.881804Z"},"trusted":true},"outputs":[],"source":["without_mask_data = os.listdir('/kaggle/input/face-mask-dataset/data/without_mask/')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:19:14.902203Z","iopub.status.busy":"2023-09-18T15:19:14.901079Z","iopub.status.idle":"2023-09-18T15:19:14.909970Z","shell.execute_reply":"2023-09-18T15:19:14.908511Z","shell.execute_reply.started":"2023-09-18T15:19:14.902149Z"},"trusted":true},"outputs":[],"source":["print(\"Number of with mask Images:\", len(with_mask_data))\n","print(\"Number of without mask Images:\", len(without_mask_data))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:19:14.913239Z","iopub.status.busy":"2023-09-18T15:19:14.911914Z","iopub.status.idle":"2023-09-18T15:19:14.922879Z","shell.execute_reply":"2023-09-18T15:19:14.921776Z","shell.execute_reply.started":"2023-09-18T15:19:14.913152Z"},"trusted":true},"outputs":[],"source":["# Creating labels for with and without dataset\n","with_mask_labels = [1]*3725\n","without_mask_labels = [0]*3828\n","total_labels = with_mask_labels + without_mask_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:19:14.926196Z","iopub.status.busy":"2023-09-18T15:19:14.925638Z","iopub.status.idle":"2023-09-18T15:19:14.963379Z","shell.execute_reply":"2023-09-18T15:19:14.962276Z","shell.execute_reply.started":"2023-09-18T15:19:14.926141Z"},"trusted":true},"outputs":[],"source":["# Displaying any image\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","mask_img = mpimg.imread('/kaggle/input/face-mask-dataset/data/with_mask/with_mask_1.jpg')\n","unmask_img = mpimg.imread('/kaggle/input/face-mask-dataset/data/without_mask/without_mask_1.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:19:14.965960Z","iopub.status.busy":"2023-09-18T15:19:14.965159Z","iopub.status.idle":"2023-09-18T15:19:15.432696Z","shell.execute_reply":"2023-09-18T15:19:15.431484Z","shell.execute_reply.started":"2023-09-18T15:19:14.965909Z"},"trusted":true},"outputs":[],"source":["imgplot1 = plt.imshow(mask_img)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:19:15.435415Z","iopub.status.busy":"2023-09-18T15:19:15.434283Z","iopub.status.idle":"2023-09-18T15:19:15.691819Z","shell.execute_reply":"2023-09-18T15:19:15.690660Z","shell.execute_reply.started":"2023-09-18T15:19:15.435357Z"},"trusted":true},"outputs":[],"source":["imgplot2 = plt.imshow(unmask_img)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T15:19:15.694634Z","iopub.status.busy":"2023-09-18T15:19:15.693431Z"},"trusted":true},"outputs":[],"source":["# Processing the Images : resizing and converting to numpy arrays\n","from PIL import Image\n","import numpy as np\n","\n","data = []\n","img_path1 = '/kaggle/input/face-mask-dataset/data/with_mask/'\n","for img_files in with_mask_data:\n","    image = Image.open(img_path1 + img_files)\n","    image = image.resize((128,128))\n","    image = image.convert('RGB')\n","    image = np.array(image)\n","    data.append(image)\n","    \n","img_path2 = '/kaggle/input/face-mask-dataset/data/without_mask/'\n","for img_files in without_mask_data:\n","    image = Image.open(img_path2 + img_files)\n","    image = image.resize((128,128))\n","    image = image.convert('RGB')\n","    image = np.array(image)\n","    data.append(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Dependent and Independent variables\n","\n","X = np.array(data)\n","y = np.array(total_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train-Test split and rescaling the Independent variables\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n","\n","X_train_scaled = X_train/255\n","X_test_scaled = X_test/255"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Building the convolutional Neural networks\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","model = keras.Sequential()\n","\n","model.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(128,128,3)))\n","model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n","\n","\n","model.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n","model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(keras.layers.Flatten())\n","\n","model.add(keras.layers.Dense(128, activation='relu'))\n","model.add(keras.layers.Dropout(0.5))\n","\n","model.add(keras.layers.Dense(64, activation='relu'))\n","model.add(keras.layers.Dropout(0.5))\n","\n","\n","model.add(keras.layers.Dense(2, activation='sigmoid'))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Compiling the Neural Network\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['acc'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Training the Neural Network\n","history = model.fit(X_train_scaled, y_train, validation_split=0.1, epochs=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Model Evaluation\n","loss, accuracy = model.evaluate(X_test_scaled, y_test)\n","print(\"The Accuracy of the model is : \", accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Plotting the loss and accuracy\n","h = history\n","\n","# plot the loss value\n","plt.plot(h.history['loss'], label='train loss')\n","plt.plot(h.history['val_loss'], label='validation loss')\n","plt.legend()\n","plt.show()\n","\n","# plot the accuracy value\n","plt.plot(h.history['acc'], label='train accuracy')\n","plt.plot(h.history['val_acc'], label='validation accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Making predictions\n","import cv2\n","input_image_path = input('Path of the image to be predicted: ')\n","input_image = cv2.imread(input_image_path)\n","input_image_resized = cv2.resize(input_image, (128,128))\n","input_image_scaled = input_image_resized/255\n","input_image_reshaped = np.reshape(input_image_scaled, [1,128,128,3])\n","input_prediction = model.predict(input_image_reshaped)\n","print(input_prediction)\n","input_pred_label = np.argmax(input_prediction)\n","print(input_pred_label)\n","cv2.imshow(\"Input Image\", input_image_path)\n","\n","if input_pred_label == 1:\n","  print('The person in the image is wearing a mask')\n","else:\n","  print('The person in the image is not wearing a mask')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
